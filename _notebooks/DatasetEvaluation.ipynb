{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import pandas as pd\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"DejaVu Sans\",\n",
    "    \"font.size\": 12,\n",
    "})\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{bm}')\n",
    "figsize = 7\n",
    "\n",
    "#%matplotlib inline \n",
    "#%matplotlib widget\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28be9c",
   "metadata": {},
   "source": [
    "### Study distance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a11574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distances of reflected vs. original\n",
    "from poly_certificate.problem import generate_distances, Problem\n",
    "from _scripts.evaluate_real import ANCHOR_CHOICE\n",
    "\n",
    "dataset = \"trial5\"\n",
    "use_anchors = ANCHOR_CHOICE[\"top\"]\n",
    "\n",
    "prob = Problem.init_from_dataset(dataset, \n",
    "                                 time_range=None, \n",
    "                                 use_anchors=use_anchors,\n",
    "                                 use_gt=False)\n",
    "\n",
    "def plot_distribution(prob):\n",
    "    D_real = generate_distances(prob.trajectory,  prob.anchors)\n",
    "    D_noisy = prob.D_noisy.copy()\n",
    "    D_noisy[D_noisy > 0] = np.sqrt(D_noisy[D_noisy > 0])\n",
    "\n",
    "    fig_hist, axs_hist = plt.subplots(prob.anchors.shape[0], sharey=True, sharex=True)\n",
    "    fig, axs = plt.subplots(prob.anchors.shape[0], sharey=True, sharex=True)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    fig_hist.set_size_inches(10, 10)\n",
    "    \n",
    "    var_biased = []\n",
    "    var_unbiased = []\n",
    "    for i in range(prob.anchors.shape[0]):\n",
    "        indices = np.where(prob.D_noisy[i, :] > 0)[0]\n",
    "        axs[i].plot(prob.times[indices],D_real[i, indices], ls=\"-\", label=\"real\", color=\"k\")\n",
    "        axs[i].scatter(prob.times[indices],D_noisy[i, indices], s=1.0, label=\"noisy\", color=\"C1\")\n",
    "\n",
    "        error = D_noisy[i, indices] - D_real[i, indices]\n",
    "        var_biased.append(np.mean(error**2))\n",
    "        var_unbiased.append(np.mean((error - np.mean(error))**2))\n",
    "        axs_hist[i].hist(error)\n",
    "        axs_hist[i].set_ylabel(f\"a{i}\")\n",
    "\n",
    "        axs[i].set_ylabel(f\"a{i}\")\n",
    "        axs[i].grid()\n",
    "        \n",
    "    print(\"biased variance:\", np.round(var_biased, 2))\n",
    "    print(\"unbiased variance:\", np.round(var_unbiased, 2))\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    axs[0].set_title(\"distances over time\")\n",
    "    axs[i].set_xlabel(\"time [s]\")\n",
    "    axs[i].legend()\n",
    "\n",
    "    fig_hist.tight_layout()\n",
    "    axs_hist[0].set_title(\"error histograms\")\n",
    "    axs_hist[i].set_xlabel(\"distance error [m]\")\n",
    "    \n",
    "plot_distribution(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = Problem.init_from_dataset(dataset, \n",
    "                                 time_range=None, \n",
    "                                 use_anchors=use_anchors,\n",
    "                                 use_gt=False, \n",
    "                                 calibrate=True)\n",
    "plot_distribution(prob)\n",
    "\n",
    "D_real = generate_distances(prob.trajectory, prob.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset statistics\n",
    "for i in range(1, 17):\n",
    "    dataset = f\"trial{i}\"\n",
    "    print(f\"\\n\\n dataset {dataset}\")\n",
    "    prob = Problem.init_from_dataset(dataset, traj_only=False, use_anchors=use_anchors)\n",
    "    print(prob.E)\n",
    "    print(prob.anchors.shape)\n",
    "    ttot =  prob.times[-1]-prob.times[0]\n",
    "    print(\"total time and N:\", ttot, prob.N)\n",
    "    print(\"average frequency:\", prob.N / ttot)\n",
    "    print(\"frequency per anchor:\")\n",
    "    for a in range(prob.W.shape[0]):\n",
    "        print(f\"a{a} : {np.sum(prob.W[a, :]) / ttot:.2f}\", end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997f013",
   "metadata": {},
   "source": [
    "### Study velocity profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a468d63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# compare distances of reflected vs. original\n",
    "from poly_certificate.problem import generate_distances, Problem\n",
    "\n",
    "time_range = None #[10, 20]\n",
    "datasets = [f\"trial{i}\" for i in range(1, 2)]\n",
    "fig, axs = plt.subplots(len(datasets), sharex=True, squeeze=False)\n",
    "axs=axs.flatten()\n",
    "fig.set_size_inches(10, 2*(len(datasets)))\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    prob = Problem.init_from_dataset(dataset, \n",
    "                                     time_range=time_range, \n",
    "                                     use_anchors=use_anchors,\n",
    "                                     use_gt=False)\n",
    "    velocities = (prob.trajectory[1:] - prob.trajectory[:-1]) / (prob.times[1:] - prob.times[:-1])[:, None]\n",
    "    velocities_mag = np.linalg.norm(velocities, axis=1)\n",
    "    axs[i].plot(prob.times[1:],velocities_mag)\n",
    "    axs[i].axvline(prob.times[0] + 8, color=\"C1\")\n",
    "    axs[i].axvline(prob.times[-1] - 8, color=\"C1\")\n",
    "    axs[i].set_ylabel(f\"v [m/s], {dataset}\")\n",
    "    axs[i].set_ylim(0, 2)\n",
    "    axs[i].grid()\n",
    "fig.tight_layout()\n",
    "axs[0].set_title(\"velocities over time\")\n",
    "axs[i].set_xlabel(\"time [s]\")\n",
    "\n",
    "if len(datasets) == 16:\n",
    "    from poly_certificate.utils.plotting_tools import savefig\n",
    "    savefig(fig, \"_plots/velocity-profiles.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5720e8",
   "metadata": {},
   "source": [
    "## Finding local minima\n",
    "\n",
    "### compute reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd57bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.problem import Problem, generate_distances\n",
    "\n",
    "prob = Problem.init_from_dataset(\"trial1\", sigma_dist_est=0.1, sigma_acc_est=0.2, \n",
    "                                 time_range=[10, 20], \n",
    "                                 #use_anchors=None)\n",
    "                                 #use_gt=True)\n",
    "                                 use_anchors=use_anchors) # top\n",
    "                                 #use_anchors=[0, 1, 3, 4]) #diagonal)\n",
    "\n",
    "traj = prob.trajectory.copy() \n",
    "\n",
    "def plot_xy_xz(points, axs=None, **kwargs):\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(1 ,2)\n",
    "    axs[0].plot(points[:, 0], points[:, 1], **kwargs)\n",
    "    axs[0].axis(\"equal\")\n",
    "    axs[0].set_xlabel(\"x\")\n",
    "    axs[0].set_ylabel(\"y\")\n",
    "    axs[1].plot(points[:, 0], points[:, 2], **kwargs)\n",
    "    axs[1].axis(\"equal\")\n",
    "    axs[1].set_xlabel(\"x\")\n",
    "    axs[1].set_ylabel(\"z\")\n",
    "    return axs\n",
    "\n",
    "axs = plot_xy_xz(traj)\n",
    "\n",
    "axs[0].scatter(prob.anchors[:, 0], prob.anchors[:, 1])\n",
    "axs[1].scatter(prob.anchors[:, 0], prob.anchors[:, 2])\n",
    "\n",
    "#traj_refl = reflect_points(prob.trajectory.T, prob.anchors.T, verbose=True).T\n",
    "traj_refl = prob.reflected_init(fraction=1.0)\n",
    "plot_xy_xz(traj_refl, axs=axs)\n",
    "\n",
    "traj_part = prob.reflected_init(fraction=0.5)\n",
    "plot_xy_xz(traj_part, axs=axs, ls=\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f864325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.utils.plotting_tools import plot_3d_curves\n",
    "plot_3d_curves({\"original\": traj, \"reflected\":traj_refl}, anchors=prob.anchors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7329a6",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c369d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.gauss_newton import gauss_newton\n",
    "from poly_certificate.certificate import get_certificate, get_rho_and_lambdas\n",
    "regularization = \"constant-velocity\"\n",
    "#time_range = [10, 20]\n",
    "time_range = None\n",
    "#use_anchors = range(6) # all anchors\n",
    "use_anchors = [0, 2, 3, 5] # all top anchors\n",
    "#use_anchors = [0, 1, 3, 4] # diagonal anchors\n",
    "\n",
    "#sigma_dist_est = 0.05\n",
    "#calibrate = False\n",
    "\n",
    "sigma_dist_est = 0.05\n",
    "calibrate = True\n",
    "\n",
    "REG = 1e-3\n",
    "use_gt = False\n",
    "sigma_acc_est = 1e-3\n",
    "extra_noise = 0 # only split between no convergence / convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47c37d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = \"trial1\"\n",
    "\n",
    "np.random.seed(0)\n",
    "prob = Problem.init_from_dataset(\n",
    "    dataset,\n",
    "    time_range=time_range,\n",
    "    sigma_dist_est=sigma_dist_est,\n",
    "    sigma_acc_est=sigma_acc_est,\n",
    "    use_gt=use_gt,\n",
    "    use_anchors=use_anchors,\n",
    "    calibrate=calibrate\n",
    ")\n",
    "traj = prob.trajectory\n",
    "\n",
    "# yield local:\n",
    "#theta_0 = prob.random_init(regularization) \n",
    "#theta_0 = prob.reflected_init(regularization, fraction=0.5)\n",
    "#theta_0 = prob.reflected_init(regularization, fraction=1.0)\n",
    "#prob.D_noisy += np.random.normal(loc=0, scale=extra_noise, size=prob.D_noisy.shape)\n",
    "\n",
    "# yields global:\n",
    "theta_0 = prob.gt_init(regularization, extra_noise=0)#0.2)\n",
    "\n",
    "theta_hat, stats = gauss_newton(\n",
    "    theta_0, prob, regularization=regularization, max_iter=100, verbose=False,\n",
    "    tol=1e-5, progressbar=True\n",
    ")\n",
    "if stats[\"success\"] is False:\n",
    "    print(\"Gauss-Newton did not converge.\")\n",
    "else:\n",
    "    print(\"Gauss-Newton converged in\", stats[\"n it\"])\n",
    "print(\"rho, lambdas\")\n",
    "rho, lambdas = get_rho_and_lambdas(\n",
    "    theta_hat, prob, regularization=regularization\n",
    ")\n",
    "\n",
    "traj_hat = theta_hat[:, : prob.d]\n",
    "error = np.linalg.norm(traj_hat - prob.trajectory) / np.sqrt(\n",
    "    prob.N * prob.d\n",
    ")\n",
    "print(\"RMSE:\", error)\n",
    "cert = get_certificate(\n",
    "    prob,\n",
    "    rho,\n",
    "    lambdas,\n",
    "    regularization=regularization,\n",
    "    reg=REG,\n",
    "    verbose=False\n",
    ")\n",
    "print(\"Certificate:\", cert)\n",
    "\n",
    "traj_0 = theta_0[:, :prob.d]\n",
    "plot_3d_curves({\"original\": traj, \"estimate\":traj_hat}, anchors=prob.anchors)\n",
    "#plot_3d_curves({\"original\": traj, \"estimate\":traj_hat}, anchors=anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a9e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = stats[\"grad\"].reshape((prob.N, -1))\n",
    "mask = np.abs(grad) > 1e-6\n",
    "print(\"maximum gradient\", np.max(grad[mask]))\n",
    "I, J = np.where(mask > 0)\n",
    "fig, ax = plt.subplots()\n",
    "ax.pcolorfast(mask)\n",
    "\n",
    "traj_problem = traj_hat[I, :]\n",
    "\n",
    "plot_3d_curves({\"original\": traj, \"estimate\":traj_hat, \"problem\":traj_problem}, anchors=prob.anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de688021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of two terms\n",
    "from poly_certificate.sdp_setup import get_f\n",
    "from poly_certificate.sdp_setup import get_prob_matrices\n",
    "Q, A_0, A_list, R = get_prob_matrices(prob, regularization)\n",
    "f_hat = get_f(theta_hat)\n",
    "print(f_hat.T @ Q @ f_hat)\n",
    "print(f_hat.T @ R @ f_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c240c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.sdp_setup import get_prob_matrices, get_H\n",
    "from poly_certificate.certificate import get_block_matrices\n",
    "from poly_certificate.decompositions import get_matrix_from_blocks\n",
    "\n",
    "if prob.N < 500:\n",
    "    print(\"Comparing certificate with eigenvalues of H, size:\", prob.N)\n",
    "    Q, A_0, A_list, R = get_prob_matrices(prob, regularization)\n",
    "    H = get_H(Q + R, A_0, A_list, rho, lambdas)\n",
    "    H_ii, H_ij, h_i_list, h = get_block_matrices(prob, rho, lambdas)\n",
    "\n",
    "    H_blocks = get_matrix_from_blocks(H_ii, H_ij, h_i_list, h)\n",
    "\n",
    "    np.testing.assert_allclose(H_blocks, H.toarray())\n",
    "    print(\"Eigenvalues of H:\", np.linalg.eigvalsh(H_blocks))\n",
    "\n",
    "    np.seterr(divide='ignore')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4)\n",
    "    fig.set_size_inches(8, 3)\n",
    "    fig.tight_layout()\n",
    "    axs[0].matshow(np.log10(np.abs(Q[:20, :20].toarray())))\n",
    "    axs[1].matshow(np.log10(np.abs(R[:20, :20].toarray())))\n",
    "    axs[2].matshow(np.log10(np.abs(H[:20, :20].toarray())))\n",
    "    axs[2].set_title(\"sum of Q and R\")\n",
    "    axs[3].matshow(np.log10(np.abs(H_blocks[:20, :20])))\n",
    "    axs[3].set_title(\"from blocks\")\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4)\n",
    "    fig.set_size_inches(8, 3)\n",
    "    fig.tight_layout()\n",
    "    axs[0].matshow(np.log10(np.abs(Q[-20:, -20:].toarray())))\n",
    "    axs[1].matshow(np.log10(np.abs(R[-20:, -20:].toarray())))\n",
    "    axs[2].matshow(np.log10(np.abs(H[-20:, -20:].toarray())))\n",
    "    axs[2].set_title(\"sum of Q and R\")\n",
    "    axs[3].matshow(np.log10(np.abs(H_blocks[-20:, -20:])))\n",
    "    axs[3].set_title(\"from blocks\")\n",
    "else:\n",
    "    print(\"N is too big for eigenvalue computation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fc697e",
   "metadata": {},
   "source": [
    "### calibration\n",
    "\n",
    "determine the sigma to minimize rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.certificate import get_certificate\n",
    "\n",
    "def calibrate_sigma(use_anchors, calibrate, sigma_dist_est, sigma_acc_est_list, use_gt=False):\n",
    "    time_range = None #[10, 50]\n",
    "    dataset = \"trial1\"\n",
    "    regularization = \"constant-velocity\"\n",
    "    \n",
    "    #sigma_acc_est_list = [0.0001, 0.0003, 0.0005, 0.001, 0.003] #np.arange(0.001, 0.01, step=0.002)\n",
    "\n",
    "    rmses = np.full(len(sigma_acc_est_list), np.nan)\n",
    "    costs = np.full(len(sigma_acc_est_list), np.nan)\n",
    "    rhos = np.full(len(sigma_acc_est_list), np.nan)\n",
    "    certs = np.full(len(sigma_acc_est_list), np.nan)\n",
    "\n",
    "    for i, sigma_acc_est in enumerate(sigma_acc_est_list):\n",
    "        print(f\" sigma = {sigma_acc_est:.1e}\")\n",
    "        prob = Problem.init_from_dataset(\n",
    "            dataset,\n",
    "            time_range=time_range,\n",
    "            sigma_dist_est=sigma_dist_est,\n",
    "            sigma_acc_est=sigma_acc_est,\n",
    "            use_gt=use_gt,\n",
    "            use_anchors=use_anchors, \n",
    "            calibrate=calibrate\n",
    "        )\n",
    "        traj = prob.trajectory\n",
    "        if use_gt:\n",
    "            prob.add_noise(sigma_dist_est)\n",
    "\n",
    "        theta_0 = prob.gt_init(regularization)\n",
    "\n",
    "        theta_hat, stats = gauss_newton(\n",
    "            theta_0, prob, regularization=regularization, \n",
    "        )\n",
    "\n",
    "        if theta_hat is None:\n",
    "            print(\"unsuccessful\")\n",
    "            continue\n",
    "\n",
    "        costs[i] = stats[\"cost\"]\n",
    "\n",
    "        rho, lambdas = get_rho_and_lambdas(\n",
    "            theta_hat, prob, regularization=regularization\n",
    "        )\n",
    "        rhos[i] = -rho\n",
    "        cert = get_certificate(prob, rho, lambdas, regularization=regularization, reg=1e-3)\n",
    "        if cert > -np.inf:\n",
    "            certs[i] = cert\n",
    "\n",
    "        traj_hat = theta_hat[:, : prob.d]\n",
    "        error = np.linalg.norm(traj_hat - prob.trajectory) / np.sqrt(prob.N)\n",
    "        rmses[i] = error\n",
    "        \n",
    "    return rmses, costs, rhos, certs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(x, rmses, costs, rhos, certs, log=False):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, certs)\n",
    "    ax.set_ylabel(\"certificate\")\n",
    "    ax.set_xlabel(\"sigma\")\n",
    "    if log:\n",
    "        ax.set_xscale(\"log\")\n",
    "    ax.grid()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, rmses)\n",
    "    if log:\n",
    "        ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"RMSE\")\n",
    "    ax.set_xlabel(\"sigma\")\n",
    "    ax.grid()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, costs, label=\"cost\")\n",
    "    ax.plot(x, rhos, ls=\":\", label=\"rho\")\n",
    "    if log:\n",
    "        ax.set_xscale(\"log\")\n",
    "    ax.set_ylabel(\"cost\")\n",
    "    ax.set_xlabel(\"sigma\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    return fig, ax \n",
    "    #return rmses, costs, rhos\n",
    "    #plot_3d_curves({\"original\": traj, \"estimate\":traj_hat}, anchors=anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix sigma_dist_est at 5cm. \n",
    "sigma_dist_est = 0.05\n",
    "use_anchors = [0, 2, 3, 5] # top\n",
    "calibrate = True\n",
    "sigma_acc_est_list1 = np.logspace(-5, 1, 7) #np.arange(0.001, 0.01, step=0.002)\n",
    "results1 = calibrate_sigma(use_anchors, calibrate, sigma_dist_est, sigma_acc_est_list1)\n",
    "\n",
    "sigma_acc_est_list2 = np.arange(1e-3, 6e-3, step=1e-3) #np.arange(0.001, 0.01, step=0.002)\n",
    "results2 = calibrate_sigma(use_anchors, calibrate, sigma_dist_est, sigma_acc_est_list2)\n",
    "rmses, costs, rhos, certs = results2\n",
    "print(\"best sigma:\", sigma_acc_est_list2[np.argmin(rmses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(sigma_acc_est_list1, *results1, log=True)\n",
    "plot_results(sigma_acc_est_list2, *results2, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the same parameters work with simulated data\n",
    "sigma_dist_est = 0.05\n",
    "use_anchors = [0, 2, 3, 5] # top\n",
    "calibrate = False\n",
    "results3 = calibrate_sigma(use_anchors, calibrate, sigma_dist_est, sigma_acc_est_list2, use_gt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd223cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(sigma_acc_est_list2, *results3, log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2242c76",
   "metadata": {},
   "source": [
    "### WIP: study the  covariance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6dca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_with_cov(theta, Cov, scaling=1.0):\n",
    "    #from poly_certificate.gauss_newton import get_hess\n",
    "    #H = get_hess(theta_hat, prob, regularization=regularization)\n",
    "    from poly_certificate.utils.plotting_tools import plot_covariance\n",
    "    \n",
    "    covariances = []\n",
    "    dim = theta_hat.shape[1]\n",
    "    for n in range(prob.N):\n",
    "        covariances.append(Cov[n*dim:n*dim + 2,n*dim:n*dim+2].toarray())\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(prob.trajectory[:, 0], prob.trajectory[:, 1], color=\"k\")\n",
    "    ax.scatter(prob.anchors[:, 0], prob.anchors[:, 1], color=\"k\", marker=\"x\")\n",
    "    ax.plot(theta_hat[:, 0], theta_hat[:, 1])\n",
    "    for i in range(prob.N)[::10]:\n",
    "        plot_covariance(Cov=covariances[i], centre=theta_hat[i, :2], scaling=scaling, ax=ax)\n",
    "    ax.axis(\"equal\")\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d343fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fix sigma_dist_est at 5cm. \n",
    "use_gt = False\n",
    "time_range = [10, 50]\n",
    "sigma_dist_est = 0.05\n",
    "\n",
    "dataset = \"trial1\"\n",
    "use_anchors = [0, 2, 3, 5] # top\n",
    "sigma_acc_est = 1e-3\n",
    "\n",
    "print(f\" sigma = {sigma_acc_est:.1e}\")\n",
    "prob = Problem.init_from_dataset(\n",
    "    dataset,\n",
    "    time_range=time_range,\n",
    "    sigma_dist_est=sigma_dist_est,\n",
    "    sigma_acc_est=sigma_acc_est,\n",
    "    use_gt=use_gt,\n",
    "    use_anchors=use_anchors,\n",
    "    calibrate=True\n",
    ")\n",
    "\n",
    "for regularization in [\"constant-velocity\", \"zero-velocity\"]:\n",
    "    theta_0 = prob.gt_init(regularization)\n",
    "    theta_hat, stats = gauss_newton(\n",
    "        theta_0, prob, regularization=regularization, max_iter=200\n",
    "    )\n",
    "\n",
    "    if theta_hat is None:\n",
    "        print(\"unsuccessful\")\n",
    "    print(\"converged\")\n",
    "\n",
    "    rho, lambdas = get_rho_and_lambdas(\n",
    "        theta_hat, prob, regularization=regularization\n",
    "    )\n",
    "\n",
    "    traj = prob.trajectory\n",
    "    traj_hat = theta_hat[:, : prob.d]\n",
    "    error = np.linalg.norm(traj_hat - prob.trajectory) / np.sqrt(prob.N)\n",
    "\n",
    "    cert = get_certificate(prob, rho, lambdas, regularization)\n",
    "    print(regularization, \"rmse\", error, \"cert\", cert)\n",
    "    \n",
    "    fig1 = plot_3d_curves({\"original\": traj, \"estimate\":traj_hat}, anchors=prob.anchors)\n",
    "    \n",
    "    print(\"calculate inverse...\")\n",
    "    import scipy.sparse.linalg as spl\n",
    "    Cov = spl.inv(stats[\"cov\"])\n",
    "    print(\"done\")\n",
    "    \n",
    "    fig2, ax = plot_with_cov(traj_hat, Cov, scaling=1e1)\n",
    "    fig2.set_size_inches(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57a470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from poly_certificate.gaussian_process import get_posterior_covariances\n",
    "from poly_certificate.problem import Problem\n",
    "from poly_certificate.utils.plotting_tools import add_scalebar, savefig, plot_covariance\n",
    "# for covariance plotting:\n",
    "# find good scaling for covariance matrix\n",
    "\n",
    "fname = \"_results/real_top_calib/results.pkl\"\n",
    "results = pd.read_pickle(fname)\n",
    "\n",
    "row = results.iloc[0]\n",
    "prob = Problem.init_from_dataset(row.dataset, traj_only=True)\n",
    "cov_inv = row[\"inverse covariance\"]\n",
    "covs = get_posterior_covariances(prob, row[\"inverse covariance\"], regularization=row.regularization)\n",
    "\n",
    "scaling = 10\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(figsize, figsize)\n",
    "ax.plot(row[\"ground truth\"][:, 0], row[\"ground truth\"][:, 1], color=\"k\", ls=\"-\")\n",
    "ax.scatter(row.estimate[:, 0], row.estimate[:, 1], color=\"C1\", s=1.0)\n",
    "select_ns = range(row.estimate.shape[0])[::10]\n",
    "print(f\"plotting {len(select_ns)} covariance estimates\")\n",
    "for n in select_ns:\n",
    "    plot_covariance(covs[n], row.estimate[n, :2], scaling, ax,\n",
    "                    facecolor=\"C1\", alpha=0.4)\n",
    "                \n",
    "ax.grid(\"on\", which=\"both\")\n",
    "ax.xaxis.set_ticks_position('none')\n",
    "ax.yaxis.set_ticks_position('none')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xlim(-4.5, 4.5)\n",
    "ax.set_ylim(-4.5, 4.5)\n",
    "ax.set_xlabel(f\"RMSE: {row.RMSE:.2f} m\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6cbfb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc19083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d7b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a14d93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
